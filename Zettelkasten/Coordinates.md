---
tags: spaces, vector
---
Let $\alpha = \{u_{1}, \cdots, u_{n}\}$ and $\beta = \{v_{1},\cdots, v_{n}\}$ be two [[Theorems and Proofs for Basis and Dimension|basis]] of a [[Vector Space|space]] $V$, let $s \in V$, then $s$ can be written as a [[Linear Combinations|linear combination]] of both $\alpha$: $s = a_{1}u_{1}+\cdots+a_{n}u_{n}$ and $\beta$: $s = b_{1}v_{1}+\cdots + b_{n}v_{n}$. We say that the **coordinates** of $s$ relative to $\alpha$, denoted by $[s]_{\alpha} = \begin{pmatrix}a_{1}\\ \vdots \\ a_{n}\end{pmatrix}$, are the [[Scalar|scalars]] multiplying the vectors of $\alpha$, same for $\beta$, $[v]_{\beta}= \begin{pmatrix}b_{1} \\ \vdots \\ b_{n}\end{pmatrix}$, these are written in [[Column Matrix]] form by convention. Notice that these two represent the *exact same vector* in space, however, it's using different referentials, $\alpha$ and $\beta$. There is a way to change from one to the other, through the [[Change of basis]] matrix.